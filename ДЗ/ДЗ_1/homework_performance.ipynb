{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIoyuP-L2U0P",
        "outputId": "73d95750-e085-4129-8473-72634e487c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA доступна: True\n",
            "GPU: Tesla T4\n",
            "\n",
            "Размер: 64x1024x1024\n",
            "Операция             |  CPU (мс) |  GPU (мс) | Ускорение\n",
            "------------------------------------------------------------\n",
            "Матричное умножение  |   2086.27 |     42.45 |     49.15x\n",
            "Сложение             |    153.50 |      2.21 |     69.55x\n",
            "Умножение            |    154.51 |      2.21 |     69.90x\n",
            "Транспонирование     |      0.02 |      0.01 |      3.08x\n",
            "Сумма                |     23.00 |      0.99 |     23.34x\n",
            "\n",
            "Размер: 128x512x512\n",
            "Операция             |  CPU (мс) |  GPU (мс) | Ускорение\n",
            "------------------------------------------------------------\n",
            "Матричное умножение  |    516.29 |     12.02 |     42.96x\n",
            "Сложение             |     74.64 |      1.11 |     67.46x\n",
            "Умножение            |     75.91 |      1.11 |     68.62x\n",
            "Транспонирование     |      0.02 |      0.01 |      2.52x\n",
            "Сумма                |     11.04 |      0.52 |     21.13x\n",
            "\n",
            "Размер: 256x256x256\n",
            "Операция             |  CPU (мс) |  GPU (мс) | Ускорение\n",
            "------------------------------------------------------------\n",
            "Матричное умножение  |    155.52 |      2.74 |     56.83x\n",
            "Сложение             |     35.85 |      0.56 |     64.34x\n",
            "Умножение            |     38.45 |      0.55 |     69.30x\n",
            "Транспонирование     |      0.02 |      0.00 |      4.12x\n",
            "Сумма                |      5.43 |      0.26 |     20.59x\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "# Задание 3: Сравнение производительности CPU vs CUDA\n",
        "\n",
        "# 3.1 Подготовка данных\n",
        "def create_tensors():\n",
        "    return {\n",
        "        \"64x1024x1024\": torch.randn(64, 1024, 1024),\n",
        "        \"128x512x512\": torch.randn(128, 512, 512),\n",
        "        \"256x256x256\": torch.randn(256, 256, 256),\n",
        "    }\n",
        "\n",
        "# 3.2 Функция измерения времени на CPU\n",
        "def time_op_cpu(op, tensor, repeats=3):\n",
        "    times = []\n",
        "    for _ in range(repeats):\n",
        "        start = time.time()\n",
        "        op(tensor)\n",
        "        times.append(time.time() - start)\n",
        "    return (sum(times) / repeats) * 1000  # время в миллисекундах\n",
        "\n",
        "# 3.2 Функция измерения времени на GPU\n",
        "def time_op_cuda(op, tensor, repeats=10):\n",
        "    torch.cuda.synchronize()\n",
        "    start_event = torch.cuda.Event(enable_timing=True)\n",
        "    end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "    start_event.record()\n",
        "    for _ in range(repeats):\n",
        "        op(tensor)\n",
        "    end_event.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    return start_event.elapsed_time(end_event) / repeats  # время в миллисекундах\n",
        "\n",
        "# 3.3 Сравнение операций\n",
        "def benchmark(tensor, device):\n",
        "    tensor = tensor.to(device)  # переносим тензор\n",
        "\n",
        "    # операции для измерения времени\n",
        "    ops = {\n",
        "        \"Матричное умножение\": lambda x: torch.matmul(x, x.transpose(-1, -2)),\n",
        "        \"Сложение\": lambda x: x + x,\n",
        "        \"Умножение\": lambda x: x * x,\n",
        "        \"Транспонирование\": lambda x: x.transpose(-1, -2),\n",
        "        \"Сумма\": lambda x: x.sum(),\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, op in ops.items():\n",
        "        if device.type == 'cuda':\n",
        "            ms = time_op_cuda(op, tensor)\n",
        "        else:\n",
        "            ms = time_op_cpu(op, tensor)\n",
        "        results[name] = ms\n",
        "    return results\n",
        "\n",
        "# Красивый вывод в таблицу\n",
        "def print_results(cpu_results, gpu_results):\n",
        "    print(f\"{'Операция':<20} | {'CPU (мс)':>9} | {'GPU (мс)':>9} | {'Ускорение':>9}\")\n",
        "    print(\"-\" * 60)\n",
        "    for op in cpu_results:\n",
        "        cpu_time = cpu_results[op]\n",
        "        gpu_time = gpu_results.get(op, None)\n",
        "        if gpu_time and gpu_time > 0:\n",
        "            speedup = cpu_time / gpu_time\n",
        "            print(f\"{op:<20} | {cpu_time:9.2f} | {gpu_time:9.2f} | {speedup:9.2f}x\")\n",
        "        else:\n",
        "            print(f\"{op:<20} | {cpu_time:9.2f} | {'-':>9} | {'-':>9}\")\n",
        "\n",
        "def main():\n",
        "    tensors = create_tensors()\n",
        "    device_cpu = torch.device('cpu')\n",
        "    device_cuda = torch.device('cuda') if torch.cuda.is_available() else None\n",
        "\n",
        "    print(f\"CUDA доступна: {torch.cuda.is_available()}\")\n",
        "    if device_cuda:\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # 3.3 Сравнение операций\n",
        "    for size_name, tensor in tensors.items():\n",
        "        print(f\"\\nРазмер: {size_name}\")\n",
        "        cpu_results = benchmark(tensor, device_cpu)\n",
        "        gpu_results = benchmark(tensor, device_cuda) if device_cuda else {}\n",
        "        print_results(cpu_results, gpu_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Анализ результатов***\n",
        "\n",
        "**Какие операции получают наибольшее ускорение на GPU?**\n",
        "\n",
        "Наибольшее ускорение демонстрируют матричное умножение и поэлементные операции — они выполняются в десятки раз быстрее по сравнению с CPU.\n",
        "\n",
        "**Почему некоторые операции могут быть медленнее на GPU?**\n",
        "\n",
        "Транспонирование почти не ускоряется, потому что оно очень простое и быстрое само по себе. А время, которое тратится на запуск работы на GPU и ожидание результата, сводит на нет всю выгоду.\n",
        "\n",
        "**Как размер матриц влияет на ускорение?**\n",
        "\n",
        "Чем больше размер матриц, тем выше ускорение, так как GPU эффективнее использует свои ресурсы при работе с большими объемами данных.\n",
        "\n",
        "**Что происходит при передаче данных между CPU и GPU?**\n",
        "\n",
        "Передача данных между CPU и GPU занимает значительное время, что может снизить общую производительность, поэтому стоит минимизировать такие операции."
      ],
      "metadata": {
        "id": "AiMyAwFJMXbF"
      }
    }
  ]
}